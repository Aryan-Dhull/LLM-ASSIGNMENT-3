{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":155810,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":132398,"modelId":155189}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch\n!pip install -q -U accelerate peft bitsandbytes transformers trl einops","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-04T16:14:18.013591Z","iopub.execute_input":"2024-11-04T16:14:18.014007Z","iopub.status.idle":"2024-11-04T16:15:05.800863Z","shell.execute_reply.started":"2024-11-04T16:14:18.013970Z","shell.execute_reply":"2024-11-04T16:15:05.799523Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport torch\nfrom datasets import load_dataset\nfrom peft import LoraConfig, prepare_model_for_kbit_training, PeftModel\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    TrainingArguments,\n    logging,\n)\nfrom trl import SFTTrainer","metadata":{"execution":{"iopub.status.busy":"2024-11-04T16:15:05.803115Z","iopub.execute_input":"2024-11-04T16:15:05.803513Z","iopub.status.idle":"2024-11-04T16:15:34.915961Z","shell.execute_reply.started":"2024-11-04T16:15:05.803470Z","shell.execute_reply":"2024-11-04T16:15:34.915039Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def select_samples(dataset, total_samples, step):\n    selected_indices = list(range(0, total_samples, step))\n    return dataset.select(selected_indices)","metadata":{"execution":{"iopub.status.busy":"2024-11-04T16:15:34.917040Z","iopub.execute_input":"2024-11-04T16:15:34.917329Z","iopub.status.idle":"2024-11-04T16:15:34.921789Z","shell.execute_reply.started":"2024-11-04T16:15:34.917297Z","shell.execute_reply":"2024-11-04T16:15:34.920906Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"snli_dataset = load_dataset(\"snli\")\n\ntrain_dataset = select_samples(snli_dataset['train'], total_samples=550000, step=550)\ntest_dataset = select_samples(snli_dataset['test'], total_samples=10000, step=100)\nval_dataset = select_samples(snli_dataset['validation'], total_samples=10000, step=100)\n\ntrain_dataset = train_dataset.map(lambda x: {'text': f\"PREMISE: {x['premise']}  HYPOTHESIS: {x['hypothesis']}  PREDICT THE LABEL (0 for entailment, 1 for neutral, 2 for contradiction):\"})\ntest_dataset = test_dataset.map(lambda x: { 'text': f\"PREMISE: {x['premise']}  HYPOTHESIS: {x['hypothesis']}  PREDICT THE LABEL (0 for entailment, 1 for neutral, 2 for contradiction):\"})\nval_dataset = val_dataset.map(lambda x: {'text': f\"PREMISE: {x['premise']}  HYPOTHESIS: {x['hypothesis']}  PREDICT THE LABEL (0 for entailment, 1 for neutral, 2 for contradiction):\"})","metadata":{"execution":{"iopub.status.busy":"2024-11-04T16:15:34.924766Z","iopub.execute_input":"2024-11-04T16:15:34.925205Z","iopub.status.idle":"2024-11-04T16:15:40.492916Z","shell.execute_reply.started":"2024-11-04T16:15:34.925151Z","shell.execute_reply":"2024-11-04T16:15:40.492014Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/16.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07deab65829346e0b9c14250d18dbc1d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/412k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e98e6f1d85aa4c0eb3499a0b839c747b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/413k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35d71ca2288040988a86d3ebc2df10d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/19.6M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d20695782b6948cdb57c4dcc367b44bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41c0a35eb4b5483aa9c0cd5a0b03fcf8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf287ac30645416b99f7c62f664445ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/550152 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eaf352512cd440e887903c7e406afeb6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6275cf7d7bf4931afbe84342c608596"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5c839f70909475da16e20e81939ac66"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad1e63874cef4e069821312a22dcb0fe"}},"metadata":{}}]},{"cell_type":"code","source":"base_model = \"microsoft/phi-2\"\ntokenizer = AutoTokenizer.from_pretrained(base_model, use_fast=True)\ntokenizer.pad_token = tokenizer.unk_token\ntokenizer.padding_side = \"right\"\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16,\n    bnb_4bit_use_double_quant=True,\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model,\n    quantization_config=bnb_config,\n    trust_remote_code=True,\n    device_map={\"\": 0}\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-04T12:44:22.815308Z","iopub.execute_input":"2024-11-04T12:44:22.816005Z","iopub.status.idle":"2024-11-04T12:53:22.268603Z","shell.execute_reply.started":"2024-11-04T12:44:22.815966Z","shell.execute_reply":"2024-11-04T12:53:22.267601Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/7.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c0785af583c4c4ab506906e3dc63d96"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"995c2e51285347f3af2441bc3178a961"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0788f1c9686246ddbe1ab09e2eb595a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"150cbcb05a1441cdb2f11fbe67f652c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/1.08k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea7a84eaccfd43e99368129c16dd7854"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f670f24716714ed08ff5680a7eb30211"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/735 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ff65765c3d944838ca9746d08b9df09"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/35.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef4045a06da44190af20723cc7a6c57d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0ebf9f148334498a80ed5913961d6c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5e9ed7cee304fe8b13b39fa15f13e60"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/564M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2037f356613c4ffcb2fc6a7f83531318"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1595bd658c0f4bb1bcd7fdd3927ca552"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aaec3e71549c48bc9c8f5e204d1ff8ab"}},"metadata":{}}]},{"cell_type":"code","source":"model.config.use_cache = False\nmodel.config.pretraining_tp = 1\nmodel = prepare_model_for_kbit_training(model, use_gradient_checkpointing=True)","metadata":{"execution":{"iopub.status.busy":"2024-11-04T12:53:37.344156Z","iopub.execute_input":"2024-11-04T12:53:37.344897Z","iopub.status.idle":"2024-11-04T12:53:37.380501Z","shell.execute_reply.started":"2024-11-04T12:53:37.344854Z","shell.execute_reply":"2024-11-04T12:53:37.379543Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def print_trainable_parameters(model):\n    trainable_params = 0\n    all_param = 0\n\n    for _, param in model.named_parameters():\n        all_param += param.numel()\n        if param.requires_grad:\n            trainable_params += param.numel()\n\n    print(f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 *  trainable_params / all_param}\")","metadata":{"execution":{"iopub.status.busy":"2024-11-04T12:53:40.121983Z","iopub.execute_input":"2024-11-04T12:53:40.122647Z","iopub.status.idle":"2024-11-04T12:53:40.127785Z","shell.execute_reply.started":"2024-11-04T12:53:40.122607Z","shell.execute_reply":"2024-11-04T12:53:40.126781Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"peft_config = LoraConfig(\n    r=32,                   # default=8, higher value for more representational capacity\n    lora_alpha=64,\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"TEXT_CLASSIFICATION_LM\",\n    target_modules=[\n        \"q_proj\",\n        \"k_proj\",\n        \"v_proj\",\n        \"o_proj\",\n        \"gate_proj\",\n        \"up_proj\",\n        \"down_proj\",\n        \"lm_head\",\n        \"dense\"\n    ]\n)\n\nmodel = PeftModel(model, peft_config)\nprint_trainable_parameters(model)","metadata":{"execution":{"iopub.status.busy":"2024-11-04T12:53:43.687643Z","iopub.execute_input":"2024-11-04T12:53:43.688027Z","iopub.status.idle":"2024-11-04T12:53:44.327402Z","shell.execute_reply.started":"2024-11-04T12:53:43.687991Z","shell.execute_reply":"2024-11-04T12:53:44.326611Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"trainable params: 22691840 || all params: 1544084480 || trainable%: 1.4695983473650354\n","output_type":"stream"}]},{"cell_type":"code","source":"training_arguments = TrainingArguments(\n    output_dir=\"./results\",\n    num_train_epochs=5,\n    fp16=False,\n    bf16=True,\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=4,\n    gradient_accumulation_steps=1,\n    gradient_checkpointing=True,\n    max_grad_norm=0.3,\n    learning_rate=2e-5,\n    weight_decay=0.001,\n    optim=\"paged_adamw_32bit\",\n    lr_scheduler_type=\"cosine\",\n    max_steps=-1,\n    warmup_ratio=0.03,\n    group_by_length=True,\n    save_strategy=\"epoch\",\n    logging_strategy=\"steps\",\n    logging_steps=25,\n    evaluation_strategy=\"steps\",  # Evaluate during training at each eval_step\n    eval_steps=25                 # Frequency of evaluation\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-04T14:05:44.191589Z","iopub.execute_input":"2024-11-04T14:05:44.192454Z","iopub.status.idle":"2024-11-04T14:05:44.232748Z","shell.execute_reply.started":"2024-11-04T14:05:44.192414Z","shell.execute_reply":"2024-11-04T14:05:44.231760Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer = SFTTrainer(\n    model=model,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,  # Include validation dataset for evaluations during training\n    peft_config=peft_config,\n    dataset_text_field=\"text\",  # Use appropriate fields for NLI tasks ('premise', 'hypothesis', 'label')\n    tokenizer=tokenizer,\n    max_seq_length= None,\n    args=training_arguments,\n)\n\ntrainer.can_return_loss=True","metadata":{"execution":{"iopub.status.busy":"2024-11-04T14:05:49.330964Z","iopub.execute_input":"2024-11-04T14:05:49.331916Z","iopub.status.idle":"2024-11-04T14:05:50.044870Z","shell.execute_reply.started":"2024-11-04T14:05:49.331860Z","shell.execute_reply":"2024-11-04T14:05:50.044054Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field. Will not be supported from version '0.13.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:309: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25c646d9e8dd483aa8c66e3ba80df88e"}},"metadata":{}}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-11-04T14:05:55.763745Z","iopub.execute_input":"2024-11-04T14:05:55.764145Z","iopub.status.idle":"2024-11-04T15:12:00.774139Z","shell.execute_reply.started":"2024-11-04T14:05:55.764108Z","shell.execute_reply":"2024-11-04T15:12:00.773204Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stderr","text":"`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1250/1250 1:06:00, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>25</td>\n      <td>3.022900</td>\n      <td>2.985771</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>3.006900</td>\n      <td>2.867159</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>2.772800</td>\n      <td>2.573908</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>2.455200</td>\n      <td>2.276181</td>\n    </tr>\n    <tr>\n      <td>125</td>\n      <td>2.244600</td>\n      <td>2.108260</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>2.112900</td>\n      <td>2.064806</td>\n    </tr>\n    <tr>\n      <td>175</td>\n      <td>2.168600</td>\n      <td>2.042719</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>1.940300</td>\n      <td>1.987384</td>\n    </tr>\n    <tr>\n      <td>225</td>\n      <td>2.118800</td>\n      <td>2.031471</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>1.989700</td>\n      <td>2.039788</td>\n    </tr>\n    <tr>\n      <td>275</td>\n      <td>2.022300</td>\n      <td>2.035680</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>2.012300</td>\n      <td>2.049987</td>\n    </tr>\n    <tr>\n      <td>325</td>\n      <td>2.198200</td>\n      <td>2.042653</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>2.024800</td>\n      <td>2.028655</td>\n    </tr>\n    <tr>\n      <td>375</td>\n      <td>2.233100</td>\n      <td>2.105074</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>2.093100</td>\n      <td>2.153157</td>\n    </tr>\n    <tr>\n      <td>425</td>\n      <td>2.207200</td>\n      <td>2.018945</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>1.991300</td>\n      <td>1.987290</td>\n    </tr>\n    <tr>\n      <td>475</td>\n      <td>2.149000</td>\n      <td>1.979921</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>1.899500</td>\n      <td>1.935587</td>\n    </tr>\n    <tr>\n      <td>525</td>\n      <td>2.058400</td>\n      <td>1.887830</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>1.831400</td>\n      <td>1.870411</td>\n    </tr>\n    <tr>\n      <td>575</td>\n      <td>1.985900</td>\n      <td>1.858421</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>1.788900</td>\n      <td>1.829988</td>\n    </tr>\n    <tr>\n      <td>625</td>\n      <td>2.059600</td>\n      <td>1.812616</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>1.738700</td>\n      <td>1.799150</td>\n    </tr>\n    <tr>\n      <td>675</td>\n      <td>1.976800</td>\n      <td>1.784089</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>1.706600</td>\n      <td>1.760450</td>\n    </tr>\n    <tr>\n      <td>725</td>\n      <td>1.937100</td>\n      <td>1.751784</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>1.685500</td>\n      <td>1.736747</td>\n    </tr>\n    <tr>\n      <td>775</td>\n      <td>1.906100</td>\n      <td>1.743262</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>1.651500</td>\n      <td>1.719224</td>\n    </tr>\n    <tr>\n      <td>825</td>\n      <td>1.922400</td>\n      <td>1.706727</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>1.668000</td>\n      <td>1.697895</td>\n    </tr>\n    <tr>\n      <td>875</td>\n      <td>1.809500</td>\n      <td>1.682063</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>1.621700</td>\n      <td>1.676704</td>\n    </tr>\n    <tr>\n      <td>925</td>\n      <td>1.877400</td>\n      <td>1.670713</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>1.617700</td>\n      <td>1.662703</td>\n    </tr>\n    <tr>\n      <td>975</td>\n      <td>1.830600</td>\n      <td>1.653891</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>1.571800</td>\n      <td>1.653690</td>\n    </tr>\n    <tr>\n      <td>1025</td>\n      <td>1.850700</td>\n      <td>1.648292</td>\n    </tr>\n    <tr>\n      <td>1050</td>\n      <td>1.569500</td>\n      <td>1.651673</td>\n    </tr>\n    <tr>\n      <td>1075</td>\n      <td>1.830800</td>\n      <td>1.649338</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>1.629700</td>\n      <td>1.654369</td>\n    </tr>\n    <tr>\n      <td>1125</td>\n      <td>1.759900</td>\n      <td>1.649850</td>\n    </tr>\n    <tr>\n      <td>1150</td>\n      <td>1.514500</td>\n      <td>1.647922</td>\n    </tr>\n    <tr>\n      <td>1175</td>\n      <td>1.806700</td>\n      <td>1.650406</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>1.583700</td>\n      <td>1.646994</td>\n    </tr>\n    <tr>\n      <td>1225</td>\n      <td>1.827300</td>\n      <td>1.649128</td>\n    </tr>\n    <tr>\n      <td>1250</td>\n      <td>1.629500</td>\n      <td>1.649428</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:227: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:227: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:227: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:227: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:227: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:227: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","output_type":"stream"},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1250, training_loss=1.958230551147461, metrics={'train_runtime': 3964.1522, 'train_samples_per_second': 1.261, 'train_steps_per_second': 0.315, 'total_flos': 4556902151208960.0, 'train_loss': 1.958230551147461, 'epoch': 5.0})"},"metadata":{}}]},{"cell_type":"code","source":"final_model_path = \"./phi2-final\"\ntrainer.model.save_pretrained(final_model_path)","metadata":{"execution":{"iopub.status.busy":"2024-11-04T15:12:50.176498Z","iopub.execute_input":"2024-11-04T15:12:50.177180Z","iopub.status.idle":"2024-11-04T15:12:51.082079Z","shell.execute_reply.started":"2024-11-04T15:12:50.177139Z","shell.execute_reply":"2024-11-04T15:12:51.080775Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:227: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","output_type":"stream"}]},{"cell_type":"code","source":"base_model = \"microsoft/phi-2\"\ntokenizer = AutoTokenizer.from_pretrained(base_model, use_fast=True)\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = \"right\"\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16,\n    bnb_4bit_use_double_quant=True,\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model,\n    quantization_config=bnb_config,\n    device_map=\"auto\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-04T16:17:18.885575Z","iopub.execute_input":"2024-11-04T16:17:18.885982Z","iopub.status.idle":"2024-11-04T16:18:07.104108Z","shell.execute_reply.started":"2024-11-04T16:17:18.885944Z","shell.execute_reply":"2024-11-04T16:18:07.103107Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00f975b8a27142d3bd139f50d4e6ca07"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:  75%|#######4  | 3.73G/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4aaa762cd7e45188e33011786042135"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/564M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f4e533dba574e8eb30d16e4a5ac2025"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad7ce7dab3d0481cbef4805120327dba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb26d4f4080c4d06833d483893464ff3"}},"metadata":{}}]},{"cell_type":"code","source":"ft_model = PeftModel.from_pretrained(model,\"/kaggle/input/phi-2-snli-final/transformers/default/1/phi-2-snli-final\")","metadata":{"execution":{"iopub.status.busy":"2024-11-04T16:19:50.876419Z","iopub.execute_input":"2024-11-04T16:19:50.877457Z","iopub.status.idle":"2024-11-04T16:19:56.347500Z","shell.execute_reply.started":"2024-11-04T16:19:50.877406Z","shell.execute_reply":"2024-11-04T16:19:56.346636Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"import re\nfrom tqdm import tqdm\nimport torch\n\nlabel_mapping = {\n    0: \"entailment\",\n    1: \"neutral\",\n    2: \"contradiction\"\n}","metadata":{"execution":{"iopub.status.busy":"2024-11-04T16:19:59.171429Z","iopub.execute_input":"2024-11-04T16:19:59.171867Z","iopub.status.idle":"2024-11-04T16:19:59.176906Z","shell.execute_reply.started":"2024-11-04T16:19:59.171824Z","shell.execute_reply":"2024-11-04T16:19:59.176011Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def extract_label_from_output(output):\n    # Adjust the regex to allow optional quotation marks around the answer\n    match = re.search(r'Answer:\\s*\"?\\b(entailment|contradiction|neutral)\\b\"?', output, re.IGNORECASE)\n    if match:\n        return match.group(1).lower()  # Convert to lowercase for consistency\n    # Fallback if label is unclear\n    return \"unknown\"\n\n\ndef get_model_answer(model, tokenizer, premise, hypothesis, max_length=10):\n    # Construct prompt more clearly to guide the model\n    prompt = (\n        f\"Read the following premise and hypothesis carefully, and determine their relationship.\\n\\n\"\n        f\"Premise: \\\"{premise}\\\"\\n\"\n        f\"Hypothesis: \\\"{hypothesis}\\\"\\n\\n\"\n        f\"Choose the best answer:\\n\"\n        f\"- If the hypothesis must be true based on the premise, answer \\\"entailment.\\\"\\n\"\n        f\"- If the hypothesis could be true or false based on the premise, answer \\\"neutral.\\\"\\n\"\n        f\"- If the hypothesis is false based on the premise, answer \\\"contradiction.\\\"\\n\\n\"\n        f\"Answer:\"\n    )\n\n    # Tokenize input with padding and send to model's device\n    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True).to(model.device)\n\n    # Generate model output without extra tokens\n    with torch.no_grad():\n        output = model.generate(**inputs, max_new_tokens=max_length)\n\n    # Decode response and extract clean answer\n    answer = tokenizer.decode(output[0], skip_special_tokens=True).strip()\n    predicted_label = extract_label_from_output(answer)\n#     print(f\"Model output: {answer}\\nPredicted label: {predicted_label}\\n\")\n    return predicted_label","metadata":{"execution":{"iopub.status.busy":"2024-11-04T16:20:01.180085Z","iopub.execute_input":"2024-11-04T16:20:01.180525Z","iopub.status.idle":"2024-11-04T16:20:01.189901Z","shell.execute_reply.started":"2024-11-04T16:20:01.180468Z","shell.execute_reply":"2024-11-04T16:20:01.188832Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def calculate_accuracy(model, dataset, tokenizer):\n    model.eval()\n    correct = 0\n    total = 100\n    i=1\n\n    for example in tqdm(dataset):\n        premise = example['premise']\n        hypothesis = example['hypothesis']\n        true_label_text = label_mapping[example['label']]  # Convert numerical label to text\n\n        predicted_label = get_model_answer(model, tokenizer, premise, hypothesis)\n        print(predicted_label)\n        print(true_label_text)\n        print()\n\n\n        if predicted_label == true_label_text:\n            correct += 1\n\n        # Calculate and print running accuracy at each step\n        running_accuracy = correct / i\n        print(f\"Step {i}/{total} - Running Accuracy: {running_accuracy:.2%}\")\n        i+=1\n\n    accuracy = correct / total\n    return accuracy\n","metadata":{"execution":{"iopub.status.busy":"2024-11-04T16:20:04.598367Z","iopub.execute_input":"2024-11-04T16:20:04.598825Z","iopub.status.idle":"2024-11-04T16:20:04.605883Z","shell.execute_reply.started":"2024-11-04T16:20:04.598782Z","shell.execute_reply":"2024-11-04T16:20:04.604982Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Run evaluation on the base model\nprint(\"Evaluating base model...\")\nbase_model_accuracy = calculate_accuracy(model, test_dataset, tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-11-04T13:40:43.828088Z","iopub.execute_input":"2024-11-04T13:40:43.828466Z","iopub.status.idle":"2024-11-04T13:43:09.208757Z","shell.execute_reply.started":"2024-11-04T13:40:43.828429Z","shell.execute_reply":"2024-11-04T13:43:09.207833Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Evaluating base model...\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n  1%|          | 1/100 [00:01<03:09,  1.92s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"neutral\nneutral\n\nStep 1/100 - Running Accuracy: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"  2%|â–         | 2/100 [00:03<02:39,  1.62s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nentailment\n\nStep 2/100 - Running Accuracy: 100.00%\n","output_type":"stream"},{"name":"stderr","text":"  3%|â–Ž         | 3/100 [00:04<02:28,  1.53s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nneutral\n\nStep 3/100 - Running Accuracy: 66.67%\n","output_type":"stream"},{"name":"stderr","text":"  4%|â–         | 4/100 [00:06<02:26,  1.53s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nneutral\n\nStep 4/100 - Running Accuracy: 50.00%\n","output_type":"stream"},{"name":"stderr","text":"  5%|â–Œ         | 5/100 [00:07<02:22,  1.50s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nneutral\n\nStep 5/100 - Running Accuracy: 40.00%\n","output_type":"stream"},{"name":"stderr","text":"  6%|â–Œ         | 6/100 [00:09<02:18,  1.47s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"neutral\ncontradiction\n\nStep 6/100 - Running Accuracy: 33.33%\n","output_type":"stream"},{"name":"stderr","text":"  7%|â–‹         | 7/100 [00:10<02:14,  1.45s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nneutral\n\nStep 7/100 - Running Accuracy: 28.57%\n","output_type":"stream"},{"name":"stderr","text":"  8%|â–Š         | 8/100 [00:11<02:12,  1.44s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\ncontradiction\n\nStep 8/100 - Running Accuracy: 25.00%\n","output_type":"stream"},{"name":"stderr","text":"  9%|â–‰         | 9/100 [00:13<02:10,  1.44s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nentailment\n\nStep 9/100 - Running Accuracy: 33.33%\n","output_type":"stream"},{"name":"stderr","text":" 10%|â–ˆ         | 10/100 [00:14<02:08,  1.43s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nneutral\n\nStep 10/100 - Running Accuracy: 30.00%\n","output_type":"stream"},{"name":"stderr","text":" 11%|â–ˆ         | 11/100 [00:16<02:06,  1.43s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nentailment\n\nStep 11/100 - Running Accuracy: 36.36%\n","output_type":"stream"},{"name":"stderr","text":" 12%|â–ˆâ–        | 12/100 [00:17<02:05,  1.42s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nentailment\n\nStep 12/100 - Running Accuracy: 41.67%\n","output_type":"stream"},{"name":"stderr","text":" 13%|â–ˆâ–Ž        | 13/100 [00:19<02:06,  1.46s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nentailment\n\nStep 13/100 - Running Accuracy: 46.15%\n","output_type":"stream"},{"name":"stderr","text":" 14%|â–ˆâ–        | 14/100 [00:20<02:04,  1.45s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\ncontradiction\n\nStep 14/100 - Running Accuracy: 42.86%\n","output_type":"stream"},{"name":"stderr","text":" 15%|â–ˆâ–Œ        | 15/100 [00:22<02:02,  1.44s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"neutral\nneutral\n\nStep 15/100 - Running Accuracy: 46.67%\n","output_type":"stream"},{"name":"stderr","text":" 16%|â–ˆâ–Œ        | 16/100 [00:23<01:59,  1.43s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nneutral\n\nStep 16/100 - Running Accuracy: 43.75%\n","output_type":"stream"},{"name":"stderr","text":" 17%|â–ˆâ–‹        | 17/100 [00:24<01:58,  1.43s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\ncontradiction\n\nStep 17/100 - Running Accuracy: 41.18%\n","output_type":"stream"},{"name":"stderr","text":" 18%|â–ˆâ–Š        | 18/100 [00:26<01:56,  1.43s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nentailment\n\nStep 18/100 - Running Accuracy: 44.44%\n","output_type":"stream"},{"name":"stderr","text":" 19%|â–ˆâ–‰        | 19/100 [00:27<01:55,  1.42s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nentailment\n\nStep 19/100 - Running Accuracy: 47.37%\n","output_type":"stream"},{"name":"stderr","text":" 20%|â–ˆâ–ˆ        | 20/100 [00:29<01:54,  1.43s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\ncontradiction\n\nStep 20/100 - Running Accuracy: 45.00%\n","output_type":"stream"},{"name":"stderr","text":" 21%|â–ˆâ–ˆ        | 21/100 [00:30<01:52,  1.43s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nneutral\n\nStep 21/100 - Running Accuracy: 42.86%\n","output_type":"stream"},{"name":"stderr","text":" 22%|â–ˆâ–ˆâ–       | 22/100 [00:32<01:52,  1.44s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\ncontradiction\n\nStep 22/100 - Running Accuracy: 40.91%\n","output_type":"stream"},{"name":"stderr","text":" 23%|â–ˆâ–ˆâ–Ž       | 23/100 [00:33<01:50,  1.44s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nneutral\n\nStep 23/100 - Running Accuracy: 39.13%\n","output_type":"stream"},{"name":"stderr","text":" 24%|â–ˆâ–ˆâ–       | 24/100 [00:34<01:49,  1.44s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nentailment\n\nStep 24/100 - Running Accuracy: 41.67%\n","output_type":"stream"},{"name":"stderr","text":" 25%|â–ˆâ–ˆâ–Œ       | 25/100 [00:36<01:47,  1.43s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\ncontradiction\n\nStep 25/100 - Running Accuracy: 40.00%\n","output_type":"stream"},{"name":"stderr","text":" 26%|â–ˆâ–ˆâ–Œ       | 26/100 [00:37<01:48,  1.47s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\ncontradiction\n\nStep 26/100 - Running Accuracy: 38.46%\n","output_type":"stream"},{"name":"stderr","text":" 27%|â–ˆâ–ˆâ–‹       | 27/100 [00:39<01:46,  1.47s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\ncontradiction\n\nStep 27/100 - Running Accuracy: 37.04%\n","output_type":"stream"},{"name":"stderr","text":" 28%|â–ˆâ–ˆâ–Š       | 28/100 [00:40<01:44,  1.45s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\ncontradiction\n\nStep 28/100 - Running Accuracy: 35.71%\n","output_type":"stream"},{"name":"stderr","text":" 29%|â–ˆâ–ˆâ–‰       | 29/100 [00:42<01:45,  1.48s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\ncontradiction\n\nStep 29/100 - Running Accuracy: 34.48%\n","output_type":"stream"},{"name":"stderr","text":" 30%|â–ˆâ–ˆâ–ˆ       | 30/100 [00:43<01:41,  1.46s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nentailment\n\nStep 30/100 - Running Accuracy: 36.67%\n","output_type":"stream"},{"name":"stderr","text":" 31%|â–ˆâ–ˆâ–ˆ       | 31/100 [00:45<01:39,  1.45s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nentailment\n\nStep 31/100 - Running Accuracy: 38.71%\n","output_type":"stream"},{"name":"stderr","text":" 32%|â–ˆâ–ˆâ–ˆâ–      | 32/100 [00:46<01:40,  1.48s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nentailment\n\nStep 32/100 - Running Accuracy: 40.62%\n","output_type":"stream"},{"name":"stderr","text":" 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 33/100 [00:48<01:38,  1.47s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nneutral\n\nStep 33/100 - Running Accuracy: 39.39%\n","output_type":"stream"},{"name":"stderr","text":" 34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [00:49<01:36,  1.46s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nneutral\n\nStep 34/100 - Running Accuracy: 38.24%\n","output_type":"stream"},{"name":"stderr","text":" 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 35/100 [00:50<01:34,  1.45s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"neutral\nentailment\n\nStep 35/100 - Running Accuracy: 37.14%\n","output_type":"stream"},{"name":"stderr","text":" 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 36/100 [00:52<01:32,  1.45s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\ncontradiction\n\nStep 36/100 - Running Accuracy: 36.11%\n","output_type":"stream"},{"name":"stderr","text":" 37%|â–ˆâ–ˆâ–ˆâ–‹      | 37/100 [00:53<01:30,  1.44s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nneutral\n\nStep 37/100 - Running Accuracy: 35.14%\n","output_type":"stream"},{"name":"stderr","text":" 38%|â–ˆâ–ˆâ–ˆâ–Š      | 38/100 [00:55<01:29,  1.45s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\ncontradiction\n\nStep 38/100 - Running Accuracy: 34.21%\n","output_type":"stream"},{"name":"stderr","text":" 39%|â–ˆâ–ˆâ–ˆâ–‰      | 39/100 [00:56<01:31,  1.49s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\ncontradiction\n\nStep 39/100 - Running Accuracy: 33.33%\n","output_type":"stream"},{"name":"stderr","text":" 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [00:58<01:31,  1.52s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nentailment\n\nStep 40/100 - Running Accuracy: 35.00%\n","output_type":"stream"},{"name":"stderr","text":" 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 41/100 [00:59<01:27,  1.49s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nentailment\n\nStep 41/100 - Running Accuracy: 36.59%\n","output_type":"stream"},{"name":"stderr","text":" 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/100 [01:01<01:25,  1.47s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nneutral\n\nStep 42/100 - Running Accuracy: 35.71%\n","output_type":"stream"},{"name":"stderr","text":" 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 43/100 [01:02<01:23,  1.46s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nneutral\n\nStep 43/100 - Running Accuracy: 34.88%\n","output_type":"stream"},{"name":"stderr","text":" 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/100 [01:04<01:21,  1.45s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\ncontradiction\n\nStep 44/100 - Running Accuracy: 34.09%\n","output_type":"stream"},{"name":"stderr","text":" 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 45/100 [01:05<01:19,  1.44s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nneutral\n\nStep 45/100 - Running Accuracy: 33.33%\n","output_type":"stream"},{"name":"stderr","text":" 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 46/100 [01:07<01:17,  1.44s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\ncontradiction\n\nStep 46/100 - Running Accuracy: 32.61%\n","output_type":"stream"},{"name":"stderr","text":" 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 47/100 [01:08<01:16,  1.45s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"neutral\nneutral\n\nStep 47/100 - Running Accuracy: 34.04%\n","output_type":"stream"},{"name":"stderr","text":" 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 48/100 [01:09<01:15,  1.44s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nneutral\n\nStep 48/100 - Running Accuracy: 33.33%\n","output_type":"stream"},{"name":"stderr","text":" 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49/100 [01:11<01:15,  1.47s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nneutral\n\nStep 49/100 - Running Accuracy: 32.65%\n","output_type":"stream"},{"name":"stderr","text":" 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [01:12<01:12,  1.45s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\ncontradiction\n\nStep 50/100 - Running Accuracy: 32.00%\n","output_type":"stream"},{"name":"stderr","text":" 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 51/100 [01:14<01:10,  1.44s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nentailment\n\nStep 51/100 - Running Accuracy: 33.33%\n","output_type":"stream"},{"name":"stderr","text":" 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/100 [01:15<01:09,  1.45s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\ncontradiction\n\nStep 52/100 - Running Accuracy: 32.69%\n","output_type":"stream"},{"name":"stderr","text":" 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 53/100 [01:17<01:08,  1.45s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nneutral\n\nStep 53/100 - Running Accuracy: 32.08%\n","output_type":"stream"},{"name":"stderr","text":" 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/100 [01:18<01:06,  1.45s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"neutral\ncontradiction\n\nStep 54/100 - Running Accuracy: 31.48%\n","output_type":"stream"},{"name":"stderr","text":" 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/100 [01:20<01:04,  1.44s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nneutral\n\nStep 55/100 - Running Accuracy: 30.91%\n","output_type":"stream"},{"name":"stderr","text":" 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 56/100 [01:21<01:03,  1.44s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\ncontradiction\n\nStep 56/100 - Running Accuracy: 30.36%\n","output_type":"stream"},{"name":"stderr","text":" 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 57/100 [01:22<01:01,  1.43s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"neutral\ncontradiction\n\nStep 57/100 - Running Accuracy: 29.82%\n","output_type":"stream"},{"name":"stderr","text":" 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 58/100 [01:24<01:00,  1.43s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\ncontradiction\n\nStep 58/100 - Running Accuracy: 29.31%\n","output_type":"stream"},{"name":"stderr","text":" 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 59/100 [01:26<01:01,  1.49s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\ncontradiction\n\nStep 59/100 - Running Accuracy: 28.81%\n","output_type":"stream"},{"name":"stderr","text":" 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 60/100 [01:27<00:58,  1.47s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nneutral\n\nStep 60/100 - Running Accuracy: 28.33%\n","output_type":"stream"},{"name":"stderr","text":" 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/100 [01:28<00:56,  1.46s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nentailment\n\nStep 61/100 - Running Accuracy: 29.51%\n","output_type":"stream"},{"name":"stderr","text":" 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/100 [01:30<00:54,  1.45s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nneutral\n\nStep 62/100 - Running Accuracy: 29.03%\n","output_type":"stream"},{"name":"stderr","text":" 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 63/100 [01:31<00:54,  1.48s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nentailment\n\nStep 63/100 - Running Accuracy: 30.16%\n","output_type":"stream"},{"name":"stderr","text":" 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/100 [01:33<00:52,  1.46s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nneutral\n\nStep 64/100 - Running Accuracy: 29.69%\n","output_type":"stream"},{"name":"stderr","text":" 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 65/100 [01:34<00:50,  1.44s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"neutral\ncontradiction\n\nStep 65/100 - Running Accuracy: 29.23%\n","output_type":"stream"},{"name":"stderr","text":" 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 66/100 [01:36<00:48,  1.43s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\ncontradiction\n\nStep 66/100 - Running Accuracy: 28.79%\n","output_type":"stream"},{"name":"stderr","text":" 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 67/100 [01:37<00:46,  1.42s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\ncontradiction\n\nStep 67/100 - Running Accuracy: 28.36%\n","output_type":"stream"},{"name":"stderr","text":" 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 68/100 [01:38<00:45,  1.42s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nentailment\n\nStep 68/100 - Running Accuracy: 29.41%\n","output_type":"stream"},{"name":"stderr","text":" 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 69/100 [01:40<00:44,  1.42s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"neutral\nneutral\n\nStep 69/100 - Running Accuracy: 30.43%\n","output_type":"stream"},{"name":"stderr","text":" 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 70/100 [01:41<00:43,  1.46s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nentailment\n\nStep 70/100 - Running Accuracy: 31.43%\n","output_type":"stream"},{"name":"stderr","text":" 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 71/100 [01:43<00:42,  1.45s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"neutral\nentailment\n\nStep 71/100 - Running Accuracy: 30.99%\n","output_type":"stream"},{"name":"stderr","text":" 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 72/100 [01:44<00:40,  1.45s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\ncontradiction\n\nStep 72/100 - Running Accuracy: 30.56%\n","output_type":"stream"},{"name":"stderr","text":" 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 73/100 [01:46<00:38,  1.44s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"neutral\ncontradiction\n\nStep 73/100 - Running Accuracy: 30.14%\n","output_type":"stream"},{"name":"stderr","text":" 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/100 [01:47<00:37,  1.43s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\ncontradiction\n\nStep 74/100 - Running Accuracy: 29.73%\n","output_type":"stream"},{"name":"stderr","text":" 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 75/100 [01:49<00:35,  1.44s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nneutral\n\nStep 75/100 - Running Accuracy: 29.33%\n","output_type":"stream"},{"name":"stderr","text":" 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 76/100 [01:50<00:34,  1.43s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nentailment\n\nStep 76/100 - Running Accuracy: 30.26%\n","output_type":"stream"},{"name":"stderr","text":" 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 77/100 [01:51<00:32,  1.43s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nentailment\n\nStep 77/100 - Running Accuracy: 31.17%\n","output_type":"stream"},{"name":"stderr","text":" 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 78/100 [01:53<00:31,  1.43s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"neutral\nentailment\n\nStep 78/100 - Running Accuracy: 30.77%\n","output_type":"stream"},{"name":"stderr","text":" 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79/100 [01:54<00:29,  1.42s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\ncontradiction\n\nStep 79/100 - Running Accuracy: 30.38%\n","output_type":"stream"},{"name":"stderr","text":" 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 80/100 [01:56<00:28,  1.43s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nentailment\n\nStep 80/100 - Running Accuracy: 31.25%\n","output_type":"stream"},{"name":"stderr","text":" 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 81/100 [01:57<00:27,  1.46s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\ncontradiction\n\nStep 81/100 - Running Accuracy: 30.86%\n","output_type":"stream"},{"name":"stderr","text":" 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 82/100 [01:59<00:26,  1.45s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nneutral\n\nStep 82/100 - Running Accuracy: 30.49%\n","output_type":"stream"},{"name":"stderr","text":" 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 83/100 [02:00<00:24,  1.45s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\ncontradiction\n\nStep 83/100 - Running Accuracy: 30.12%\n","output_type":"stream"},{"name":"stderr","text":" 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/100 [02:02<00:23,  1.49s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nentailment\n\nStep 84/100 - Running Accuracy: 30.95%\n","output_type":"stream"},{"name":"stderr","text":" 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 85/100 [02:03<00:22,  1.47s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"neutral\nneutral\n\nStep 85/100 - Running Accuracy: 31.76%\n","output_type":"stream"},{"name":"stderr","text":" 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 86/100 [02:05<00:20,  1.47s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nneutral\n\nStep 86/100 - Running Accuracy: 31.40%\n","output_type":"stream"},{"name":"stderr","text":" 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 87/100 [02:06<00:18,  1.46s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nentailment\n\nStep 87/100 - Running Accuracy: 32.18%\n","output_type":"stream"},{"name":"stderr","text":" 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 88/100 [02:07<00:17,  1.45s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nentailment\n\nStep 88/100 - Running Accuracy: 32.95%\n","output_type":"stream"},{"name":"stderr","text":" 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 89/100 [02:09<00:16,  1.47s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nneutral\n\nStep 89/100 - Running Accuracy: 32.58%\n","output_type":"stream"},{"name":"stderr","text":" 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 90/100 [02:10<00:14,  1.46s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nneutral\n\nStep 90/100 - Running Accuracy: 32.22%\n","output_type":"stream"},{"name":"stderr","text":" 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 91/100 [02:12<00:13,  1.45s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\ncontradiction\n\nStep 91/100 - Running Accuracy: 31.87%\n","output_type":"stream"},{"name":"stderr","text":" 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 92/100 [02:13<00:11,  1.47s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"neutral\nentailment\n\nStep 92/100 - Running Accuracy: 31.52%\n","output_type":"stream"},{"name":"stderr","text":" 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 93/100 [02:15<00:10,  1.45s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nneutral\n\nStep 93/100 - Running Accuracy: 31.18%\n","output_type":"stream"},{"name":"stderr","text":" 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/100 [02:16<00:08,  1.46s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nentailment\n\nStep 94/100 - Running Accuracy: 31.91%\n","output_type":"stream"},{"name":"stderr","text":" 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 95/100 [02:18<00:07,  1.46s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nentailment\n\nStep 95/100 - Running Accuracy: 32.63%\n","output_type":"stream"},{"name":"stderr","text":" 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 96/100 [02:19<00:05,  1.45s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nneutral\n\nStep 96/100 - Running Accuracy: 32.29%\n","output_type":"stream"},{"name":"stderr","text":" 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 97/100 [02:20<00:04,  1.44s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\ncontradiction\n\nStep 97/100 - Running Accuracy: 31.96%\n","output_type":"stream"},{"name":"stderr","text":" 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 98/100 [02:22<00:02,  1.43s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\ncontradiction\n\nStep 98/100 - Running Accuracy: 31.63%\n","output_type":"stream"},{"name":"stderr","text":" 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 99/100 [02:23<00:01,  1.43s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\ncontradiction\n\nStep 99/100 - Running Accuracy: 31.31%\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:25<00:00,  1.45s/it]","output_type":"stream"},{"name":"stdout","text":"entailment\nneutral\n\nStep 100/100 - Running Accuracy: 31.00%\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"Evaluating fine-tuned model...\")\nfine_tuned_model_accuracy = calculate_accuracy(ft_model, test_dataset, tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-11-04T16:20:07.539319Z","iopub.execute_input":"2024-11-04T16:20:07.539714Z","iopub.status.idle":"2024-11-04T16:22:27.752693Z","shell.execute_reply.started":"2024-11-04T16:20:07.539668Z","shell.execute_reply":"2024-11-04T16:22:27.751790Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Evaluating fine-tuned model...\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n  1%|          | 1/100 [00:03<05:10,  3.13s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\nneutral\n\nStep 1/100 - Running Accuracy: 0.00%\n","output_type":"stream"},{"name":"stderr","text":"  2%|â–         | 2/100 [00:04<03:25,  2.10s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nentailment\n\nStep 2/100 - Running Accuracy: 50.00%\n","output_type":"stream"},{"name":"stderr","text":"  3%|â–Ž         | 3/100 [00:05<02:50,  1.76s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\nneutral\n\nStep 3/100 - Running Accuracy: 33.33%\n","output_type":"stream"},{"name":"stderr","text":"  4%|â–         | 4/100 [00:07<02:36,  1.63s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\nneutral\n\nStep 4/100 - Running Accuracy: 25.00%\n","output_type":"stream"},{"name":"stderr","text":"  5%|â–Œ         | 5/100 [00:08<02:24,  1.52s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\nneutral\n\nStep 5/100 - Running Accuracy: 20.00%\n","output_type":"stream"},{"name":"stderr","text":"  6%|â–Œ         | 6/100 [00:09<02:18,  1.47s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\ncontradiction\n\nStep 6/100 - Running Accuracy: 33.33%\n","output_type":"stream"},{"name":"stderr","text":"  7%|â–‹         | 7/100 [00:11<02:14,  1.44s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nneutral\n\nStep 7/100 - Running Accuracy: 28.57%\n","output_type":"stream"},{"name":"stderr","text":"  8%|â–Š         | 8/100 [00:12<02:09,  1.41s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\ncontradiction\n\nStep 8/100 - Running Accuracy: 37.50%\n","output_type":"stream"},{"name":"stderr","text":"  9%|â–‰         | 9/100 [00:14<02:08,  1.41s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nentailment\n\nStep 9/100 - Running Accuracy: 44.44%\n","output_type":"stream"},{"name":"stderr","text":" 10%|â–ˆ         | 10/100 [00:15<02:04,  1.38s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nneutral\n\nStep 10/100 - Running Accuracy: 40.00%\n","output_type":"stream"},{"name":"stderr","text":" 11%|â–ˆ         | 11/100 [00:16<02:01,  1.36s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\nentailment\n\nStep 11/100 - Running Accuracy: 36.36%\n","output_type":"stream"},{"name":"stderr","text":" 12%|â–ˆâ–        | 12/100 [00:18<02:00,  1.37s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"unknown\nentailment\n\nStep 12/100 - Running Accuracy: 33.33%\n","output_type":"stream"},{"name":"stderr","text":" 13%|â–ˆâ–Ž        | 13/100 [00:19<02:01,  1.39s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"unknown\nentailment\n\nStep 13/100 - Running Accuracy: 30.77%\n","output_type":"stream"},{"name":"stderr","text":" 14%|â–ˆâ–        | 14/100 [00:20<01:59,  1.39s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\ncontradiction\n\nStep 14/100 - Running Accuracy: 35.71%\n","output_type":"stream"},{"name":"stderr","text":" 15%|â–ˆâ–Œ        | 15/100 [00:22<01:56,  1.37s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nneutral\n\nStep 15/100 - Running Accuracy: 33.33%\n","output_type":"stream"},{"name":"stderr","text":" 16%|â–ˆâ–Œ        | 16/100 [00:23<01:54,  1.37s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\nneutral\n\nStep 16/100 - Running Accuracy: 31.25%\n","output_type":"stream"},{"name":"stderr","text":" 17%|â–ˆâ–‹        | 17/100 [00:25<01:54,  1.38s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\ncontradiction\n\nStep 17/100 - Running Accuracy: 35.29%\n","output_type":"stream"},{"name":"stderr","text":" 18%|â–ˆâ–Š        | 18/100 [00:26<01:54,  1.39s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nentailment\n\nStep 18/100 - Running Accuracy: 38.89%\n","output_type":"stream"},{"name":"stderr","text":" 19%|â–ˆâ–‰        | 19/100 [00:27<01:52,  1.39s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"unknown\nentailment\n\nStep 19/100 - Running Accuracy: 36.84%\n","output_type":"stream"},{"name":"stderr","text":" 20%|â–ˆâ–ˆ        | 20/100 [00:29<01:52,  1.41s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\ncontradiction\n\nStep 20/100 - Running Accuracy: 40.00%\n","output_type":"stream"},{"name":"stderr","text":" 21%|â–ˆâ–ˆ        | 21/100 [00:30<01:51,  1.41s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nneutral\n\nStep 21/100 - Running Accuracy: 38.10%\n","output_type":"stream"},{"name":"stderr","text":" 22%|â–ˆâ–ˆâ–       | 22/100 [00:32<01:48,  1.39s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\ncontradiction\n\nStep 22/100 - Running Accuracy: 40.91%\n","output_type":"stream"},{"name":"stderr","text":" 23%|â–ˆâ–ˆâ–Ž       | 23/100 [00:33<01:45,  1.37s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"unknown\nneutral\n\nStep 23/100 - Running Accuracy: 39.13%\n","output_type":"stream"},{"name":"stderr","text":" 24%|â–ˆâ–ˆâ–       | 24/100 [00:34<01:45,  1.39s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nentailment\n\nStep 24/100 - Running Accuracy: 41.67%\n","output_type":"stream"},{"name":"stderr","text":" 25%|â–ˆâ–ˆâ–Œ       | 25/100 [00:36<01:43,  1.38s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\ncontradiction\n\nStep 25/100 - Running Accuracy: 40.00%\n","output_type":"stream"},{"name":"stderr","text":" 26%|â–ˆâ–ˆâ–Œ       | 26/100 [00:37<01:44,  1.41s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\ncontradiction\n\nStep 26/100 - Running Accuracy: 42.31%\n","output_type":"stream"},{"name":"stderr","text":" 27%|â–ˆâ–ˆâ–‹       | 27/100 [00:39<01:41,  1.39s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\ncontradiction\n\nStep 27/100 - Running Accuracy: 44.44%\n","output_type":"stream"},{"name":"stderr","text":" 28%|â–ˆâ–ˆâ–Š       | 28/100 [00:40<01:39,  1.38s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\ncontradiction\n\nStep 28/100 - Running Accuracy: 46.43%\n","output_type":"stream"},{"name":"stderr","text":" 29%|â–ˆâ–ˆâ–‰       | 29/100 [00:41<01:39,  1.39s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\ncontradiction\n\nStep 29/100 - Running Accuracy: 48.28%\n","output_type":"stream"},{"name":"stderr","text":" 30%|â–ˆâ–ˆâ–ˆ       | 30/100 [00:43<01:36,  1.38s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nentailment\n\nStep 30/100 - Running Accuracy: 50.00%\n","output_type":"stream"},{"name":"stderr","text":" 31%|â–ˆâ–ˆâ–ˆ       | 31/100 [00:44<01:34,  1.38s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nentailment\n\nStep 31/100 - Running Accuracy: 51.61%\n","output_type":"stream"},{"name":"stderr","text":" 32%|â–ˆâ–ˆâ–ˆâ–      | 32/100 [00:46<01:36,  1.42s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"unknown\nentailment\n\nStep 32/100 - Running Accuracy: 50.00%\n","output_type":"stream"},{"name":"stderr","text":" 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 33/100 [00:47<01:33,  1.40s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\nneutral\n\nStep 33/100 - Running Accuracy: 48.48%\n","output_type":"stream"},{"name":"stderr","text":" 34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [00:48<01:31,  1.39s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\nneutral\n\nStep 34/100 - Running Accuracy: 47.06%\n","output_type":"stream"},{"name":"stderr","text":" 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 35/100 [00:50<01:29,  1.38s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nentailment\n\nStep 35/100 - Running Accuracy: 48.57%\n","output_type":"stream"},{"name":"stderr","text":" 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 36/100 [00:51<01:28,  1.38s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\ncontradiction\n\nStep 36/100 - Running Accuracy: 50.00%\n","output_type":"stream"},{"name":"stderr","text":" 37%|â–ˆâ–ˆâ–ˆâ–‹      | 37/100 [00:52<01:26,  1.37s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nneutral\n\nStep 37/100 - Running Accuracy: 48.65%\n","output_type":"stream"},{"name":"stderr","text":" 38%|â–ˆâ–ˆâ–ˆâ–Š      | 38/100 [00:54<01:25,  1.37s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\ncontradiction\n\nStep 38/100 - Running Accuracy: 50.00%\n","output_type":"stream"},{"name":"stderr","text":" 39%|â–ˆâ–ˆâ–ˆâ–‰      | 39/100 [00:55<01:24,  1.39s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\ncontradiction\n\nStep 39/100 - Running Accuracy: 51.28%\n","output_type":"stream"},{"name":"stderr","text":" 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [00:57<01:24,  1.41s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nentailment\n\nStep 40/100 - Running Accuracy: 52.50%\n","output_type":"stream"},{"name":"stderr","text":" 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 41/100 [00:58<01:21,  1.38s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nentailment\n\nStep 41/100 - Running Accuracy: 53.66%\n","output_type":"stream"},{"name":"stderr","text":" 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/100 [00:59<01:19,  1.38s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nneutral\n\nStep 42/100 - Running Accuracy: 52.38%\n","output_type":"stream"},{"name":"stderr","text":" 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 43/100 [01:01<01:19,  1.40s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nneutral\n\nStep 43/100 - Running Accuracy: 51.16%\n","output_type":"stream"},{"name":"stderr","text":" 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/100 [01:02<01:17,  1.39s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\ncontradiction\n\nStep 44/100 - Running Accuracy: 52.27%\n","output_type":"stream"},{"name":"stderr","text":" 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 45/100 [01:03<01:16,  1.38s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\nneutral\n\nStep 45/100 - Running Accuracy: 51.11%\n","output_type":"stream"},{"name":"stderr","text":" 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 46/100 [01:05<01:14,  1.38s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\ncontradiction\n\nStep 46/100 - Running Accuracy: 52.17%\n","output_type":"stream"},{"name":"stderr","text":" 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 47/100 [01:06<01:12,  1.37s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"neutral\nneutral\n\nStep 47/100 - Running Accuracy: 53.19%\n","output_type":"stream"},{"name":"stderr","text":" 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 48/100 [01:08<01:11,  1.37s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\nneutral\n\nStep 48/100 - Running Accuracy: 52.08%\n","output_type":"stream"},{"name":"stderr","text":" 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49/100 [01:09<01:09,  1.36s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\nneutral\n\nStep 49/100 - Running Accuracy: 51.02%\n","output_type":"stream"},{"name":"stderr","text":" 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [01:10<01:08,  1.37s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"unknown\ncontradiction\n\nStep 50/100 - Running Accuracy: 50.00%\n","output_type":"stream"},{"name":"stderr","text":" 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 51/100 [01:12<01:07,  1.37s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nentailment\n\nStep 51/100 - Running Accuracy: 50.98%\n","output_type":"stream"},{"name":"stderr","text":" 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/100 [01:13<01:05,  1.36s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\ncontradiction\n\nStep 52/100 - Running Accuracy: 51.92%\n","output_type":"stream"},{"name":"stderr","text":" 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 53/100 [01:14<01:04,  1.37s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\nneutral\n\nStep 53/100 - Running Accuracy: 50.94%\n","output_type":"stream"},{"name":"stderr","text":" 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/100 [01:16<01:03,  1.38s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\ncontradiction\n\nStep 54/100 - Running Accuracy: 51.85%\n","output_type":"stream"},{"name":"stderr","text":" 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/100 [01:17<01:01,  1.38s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nneutral\n\nStep 55/100 - Running Accuracy: 50.91%\n","output_type":"stream"},{"name":"stderr","text":" 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 56/100 [01:19<01:01,  1.39s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\ncontradiction\n\nStep 56/100 - Running Accuracy: 51.79%\n","output_type":"stream"},{"name":"stderr","text":" 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 57/100 [01:20<00:59,  1.39s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\ncontradiction\n\nStep 57/100 - Running Accuracy: 52.63%\n","output_type":"stream"},{"name":"stderr","text":" 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 58/100 [01:21<00:58,  1.39s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\ncontradiction\n\nStep 58/100 - Running Accuracy: 53.45%\n","output_type":"stream"},{"name":"stderr","text":" 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 59/100 [01:23<00:57,  1.41s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"unknown\ncontradiction\n\nStep 59/100 - Running Accuracy: 52.54%\n","output_type":"stream"},{"name":"stderr","text":" 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 60/100 [01:24<00:56,  1.40s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"unknown\nneutral\n\nStep 60/100 - Running Accuracy: 51.67%\n","output_type":"stream"},{"name":"stderr","text":" 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/100 [01:26<00:54,  1.41s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"unknown\nentailment\n\nStep 61/100 - Running Accuracy: 50.82%\n","output_type":"stream"},{"name":"stderr","text":" 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/100 [01:27<00:53,  1.40s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"neutral\nneutral\n\nStep 62/100 - Running Accuracy: 51.61%\n","output_type":"stream"},{"name":"stderr","text":" 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 63/100 [01:29<00:52,  1.43s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\nentailment\n\nStep 63/100 - Running Accuracy: 50.79%\n","output_type":"stream"},{"name":"stderr","text":" 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/100 [01:30<00:50,  1.41s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nneutral\n\nStep 64/100 - Running Accuracy: 50.00%\n","output_type":"stream"},{"name":"stderr","text":" 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 65/100 [01:31<00:48,  1.39s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\ncontradiction\n\nStep 65/100 - Running Accuracy: 50.77%\n","output_type":"stream"},{"name":"stderr","text":" 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 66/100 [01:33<00:47,  1.41s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\ncontradiction\n\nStep 66/100 - Running Accuracy: 51.52%\n","output_type":"stream"},{"name":"stderr","text":" 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 67/100 [01:34<00:47,  1.43s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\ncontradiction\n\nStep 67/100 - Running Accuracy: 52.24%\n","output_type":"stream"},{"name":"stderr","text":" 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 68/100 [01:36<00:45,  1.42s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nentailment\n\nStep 68/100 - Running Accuracy: 52.94%\n","output_type":"stream"},{"name":"stderr","text":" 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 69/100 [01:37<00:43,  1.39s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"unknown\nneutral\n\nStep 69/100 - Running Accuracy: 52.17%\n","output_type":"stream"},{"name":"stderr","text":" 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 70/100 [01:38<00:42,  1.41s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\nentailment\n\nStep 70/100 - Running Accuracy: 51.43%\n","output_type":"stream"},{"name":"stderr","text":" 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 71/100 [01:40<00:40,  1.41s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nentailment\n\nStep 71/100 - Running Accuracy: 52.11%\n","output_type":"stream"},{"name":"stderr","text":" 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 72/100 [01:41<00:39,  1.40s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\ncontradiction\n\nStep 72/100 - Running Accuracy: 52.78%\n","output_type":"stream"},{"name":"stderr","text":" 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 73/100 [01:42<00:37,  1.38s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\ncontradiction\n\nStep 73/100 - Running Accuracy: 53.42%\n","output_type":"stream"},{"name":"stderr","text":" 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/100 [01:44<00:36,  1.40s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\ncontradiction\n\nStep 74/100 - Running Accuracy: 54.05%\n","output_type":"stream"},{"name":"stderr","text":" 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 75/100 [01:45<00:34,  1.38s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"unknown\nneutral\n\nStep 75/100 - Running Accuracy: 53.33%\n","output_type":"stream"},{"name":"stderr","text":" 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 76/100 [01:47<00:32,  1.37s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\nentailment\n\nStep 76/100 - Running Accuracy: 52.63%\n","output_type":"stream"},{"name":"stderr","text":" 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 77/100 [01:48<00:31,  1.36s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nentailment\n\nStep 77/100 - Running Accuracy: 53.25%\n","output_type":"stream"},{"name":"stderr","text":" 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 78/100 [01:49<00:29,  1.36s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"neutral\nentailment\n\nStep 78/100 - Running Accuracy: 52.56%\n","output_type":"stream"},{"name":"stderr","text":" 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79/100 [01:51<00:28,  1.37s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\ncontradiction\n\nStep 79/100 - Running Accuracy: 53.16%\n","output_type":"stream"},{"name":"stderr","text":" 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 80/100 [01:52<00:27,  1.37s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nentailment\n\nStep 80/100 - Running Accuracy: 53.75%\n","output_type":"stream"},{"name":"stderr","text":" 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 81/100 [01:53<00:26,  1.37s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\ncontradiction\n\nStep 81/100 - Running Accuracy: 54.32%\n","output_type":"stream"},{"name":"stderr","text":" 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 82/100 [01:55<00:24,  1.38s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\nneutral\n\nStep 82/100 - Running Accuracy: 53.66%\n","output_type":"stream"},{"name":"stderr","text":" 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 83/100 [01:56<00:23,  1.38s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\ncontradiction\n\nStep 83/100 - Running Accuracy: 54.22%\n","output_type":"stream"},{"name":"stderr","text":" 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/100 [01:58<00:22,  1.41s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\nentailment\n\nStep 84/100 - Running Accuracy: 53.57%\n","output_type":"stream"},{"name":"stderr","text":" 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 85/100 [01:59<00:20,  1.39s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nneutral\n\nStep 85/100 - Running Accuracy: 52.94%\n","output_type":"stream"},{"name":"stderr","text":" 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 86/100 [02:00<00:19,  1.38s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nneutral\n\nStep 86/100 - Running Accuracy: 52.33%\n","output_type":"stream"},{"name":"stderr","text":" 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 87/100 [02:02<00:17,  1.38s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\nentailment\n\nStep 87/100 - Running Accuracy: 51.72%\n","output_type":"stream"},{"name":"stderr","text":" 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 88/100 [02:03<00:16,  1.41s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\nentailment\n\nStep 88/100 - Running Accuracy: 51.14%\n","output_type":"stream"},{"name":"stderr","text":" 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 89/100 [02:05<00:15,  1.42s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nneutral\n\nStep 89/100 - Running Accuracy: 50.56%\n","output_type":"stream"},{"name":"stderr","text":" 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 90/100 [02:06<00:14,  1.40s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"unknown\nneutral\n\nStep 90/100 - Running Accuracy: 50.00%\n","output_type":"stream"},{"name":"stderr","text":" 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 91/100 [02:07<00:12,  1.38s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\ncontradiction\n\nStep 91/100 - Running Accuracy: 50.55%\n","output_type":"stream"},{"name":"stderr","text":" 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 92/100 [02:09<00:11,  1.38s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"neutral\nentailment\n\nStep 92/100 - Running Accuracy: 50.00%\n","output_type":"stream"},{"name":"stderr","text":" 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 93/100 [02:10<00:09,  1.37s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\nneutral\n\nStep 93/100 - Running Accuracy: 49.46%\n","output_type":"stream"},{"name":"stderr","text":" 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/100 [02:11<00:08,  1.37s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nentailment\n\nStep 94/100 - Running Accuracy: 50.00%\n","output_type":"stream"},{"name":"stderr","text":" 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 95/100 [02:13<00:06,  1.36s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"entailment\nentailment\n\nStep 95/100 - Running Accuracy: 50.53%\n","output_type":"stream"},{"name":"stderr","text":" 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 96/100 [02:14<00:05,  1.37s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\nneutral\n\nStep 96/100 - Running Accuracy: 50.00%\n","output_type":"stream"},{"name":"stderr","text":" 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 97/100 [02:16<00:04,  1.36s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\ncontradiction\n\nStep 97/100 - Running Accuracy: 50.52%\n","output_type":"stream"},{"name":"stderr","text":" 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 98/100 [02:17<00:02,  1.35s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\ncontradiction\n\nStep 98/100 - Running Accuracy: 51.02%\n","output_type":"stream"},{"name":"stderr","text":" 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 99/100 [02:18<00:01,  1.35s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"contradiction\ncontradiction\n\nStep 99/100 - Running Accuracy: 51.52%\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:20<00:00,  1.40s/it]","output_type":"stream"},{"name":"stdout","text":"unknown\nneutral\n\nStep 100/100 - Running Accuracy: 51.00%\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]}]}